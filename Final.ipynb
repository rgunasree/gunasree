{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPm6YpDmv18qppjx/ZVlkLH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rgunasree/gunasree/blob/main/Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from textblob import TextBlob\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "import urllib.request\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "# Define a function to extract text from a URL\n",
        "def extract_text_from_url(url):\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        text = ' '.join(soup.stripped_strings)\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f\"Error retrieving text from URL: {e}\")\n",
        "        return None\n",
        "\n",
        "# Define a function to compute derived variables\n",
        "def compute_derived_variables(text):\n",
        "    # Clean the text\n",
        "    cleaned_words = word_tokenize(text.lower())\n",
        "    cleaned_words = [word for word in cleaned_words if word.isalpha()]\n",
        "\n",
        "    # Compute positive, negative, and polarity scores\n",
        "    positive_score = TextBlob(text).sentiment.polarity\n",
        "    negative_score = TextBlob(text).sentiment.subjectivity\n",
        "    polarity_score = TextBlob(text).sentiment.polarity\n",
        "    subjectivity_score = TextBlob(text).sentiment.subjectivity\n",
        "\n",
        "    # Calculate syllable count per word\n",
        "    def syllable_count(word):\n",
        "        syllables = 0\n",
        "        vowels = \"aeiouy\"\n",
        "        if word[0] in vowels:\n",
        "            syllables += 1\n",
        "        for index in range(1, len(word)):\n",
        "            if word[index] in vowels and word[index - 1] not in vowels:\n",
        "                syllables += 1\n",
        "        if word.endswith(\"e\"):\n",
        "            syllables -= 1\n",
        "        if syllables == 0:\n",
        "            syllables += 1\n",
        "        return syllables\n",
        "\n",
        "    # Calculate syllable count per word\n",
        "    syllable_counts = [syllable_count(word) for word in cleaned_words]\n",
        "\n",
        "    # Count complex words (words with more than two syllables)\n",
        "    complex_word_count = sum(1 for syllables in syllable_counts if syllables > 2)\n",
        "\n",
        "    # Count personal pronouns\n",
        "    personal_pronouns_count = sum(1 for word in cleaned_words if word.lower() in ['i', 'we', 'my', 'ours', 'us'])\n",
        "\n",
        "    # Calculate average word length\n",
        "    total_characters = sum(len(word) for word in cleaned_words)\n",
        "    average_word_length = total_characters / len(cleaned_words)\n",
        "\n",
        "    # Calculate average sentence length\n",
        "    sentences = sent_tokenize(text)\n",
        "    average_sentence_length = sum(len(word_tokenize(sentence)) for sentence in sentences) / len(sentences)\n",
        "\n",
        "    # Calculate percentage of complex words\n",
        "    percentage_of_complex_words = (complex_word_count / len(cleaned_words)) * 100\n",
        "\n",
        "    # Calculate fog index\n",
        "    fog_index = 0.4 * (average_sentence_length + percentage_of_complex_words)\n",
        "\n",
        "    # Calculate average number of words per sentence\n",
        "    average_words_per_sentence = len(cleaned_words) / len(sentences)\n",
        "\n",
        "    # Calculate syllables per word\n",
        "    syllables_per_word = sum(syllable_counts) / len(cleaned_words)\n",
        "\n",
        "    # Return derived variables\n",
        "    derived_variables = {\n",
        "        'Positive Score': positive_score,\n",
        "        'Negative Score': negative_score,\n",
        "        'Polarity Score': polarity_score,\n",
        "        'Subjectivity Score': subjectivity_score,\n",
        "        'Average Sentence Length': average_sentence_length,\n",
        "        'Percentage of Complex Words': percentage_of_complex_words,\n",
        "        'Fog Index': fog_index,\n",
        "        'Average Number of Words Per Sentence': average_words_per_sentence,\n",
        "        'Complex Word Count': complex_word_count,\n",
        "        'Word Count': len(cleaned_words),\n",
        "        'Syllables Per Word': syllables_per_word,\n",
        "        'Personal Pronouns': personal_pronouns_count,\n",
        "        'Average Word Length': average_word_length\n",
        "    }\n",
        "\n",
        "    return derived_variables\n",
        "\n",
        "# Load the Input.xlsx file\n",
        "input_df = pd.read_excel('Input.xlsx')\n",
        "\n",
        "# Iterate over each URL and compute derived variables\n",
        "results_list = []\n",
        "for index, row in input_df.iterrows():\n",
        "    url_id = row['URL_ID']\n",
        "    url = row['URL']\n",
        "\n",
        "    # Extract text from the URL\n",
        "    text = extract_text_from_url(url)\n",
        "\n",
        "    # Compute derived variables\n",
        "    derived_variables = compute_derived_variables(text)\n",
        "    derived_variables['URL_ID'] = url_id\n",
        "    derived_variables['URL'] = url\n",
        "    results_list.append(derived_variables)\n",
        "\n",
        "# Create a DataFrame for the results\n",
        "results_columns = ['URL_ID', 'URL', 'Positive Score', 'Negative Score', 'Polarity Score', 'Subjectivity Score', 'Average Sentence Length', 'Percentage of Complex Words', 'Fog Index', 'Average Number of Words Per Sentence', 'Complex Word Count', 'Word Count', 'Syllables Per Word', 'Personal Pronouns', 'Average Word Length']\n",
        "df_results = pd.DataFrame(results_list, columns=results_columns)\n",
        "\n",
        "# Save the results to an Excel file\n",
        "df_results.to_excel('Output Data Structure.xlsx', index=False)\n",
        "\n",
        "print(\"Results saved to 'Output Data Structure.xlsx'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwEFaoDFFJoj",
        "outputId": "823a540d-afcd-4ead-b7e3-235f9a94a5e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results saved to 'Output Data Structure.xlsx'.\n"
          ]
        }
      ]
    }
  ]
}